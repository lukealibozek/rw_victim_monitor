{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schirm\n",
      "Palo Alto County Sheriff\n",
      "PKF Antares\n",
      "Legion Aero\n",
      "Vleeswarenfabriek Jac Michiels\n",
      "baysideinteriors.com\n",
      "DCI-ENGINEERS_2\n",
      "The Zalkin Law Firm P.C.\n",
      "Pharmerica.com & BrightSpring Health Services\n",
      "SIVSA\n",
      "sxi.com.ph\n",
      "coremain\n",
      "123.com\n",
      "Micro Star International ( @msigaming )\n",
      "baughmanco.com\n",
      "HEICO\n",
      "b&h pattern.inc\n",
      "SCI\n",
      "Atlantic International University\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "import re\n",
    "import json\n",
    "\n",
    "url = \"https://www.inoreader.com/stream/user/1004920918/tag/Py%3A%20Ransomware%20monitor\"\n",
    "\n",
    "# fetch the RSS feed\n",
    "response = requests.get(url)\n",
    "# print(response)\n",
    "\n",
    "# parse the XML using lxml\n",
    "root = etree.fromstring(response.content)\n",
    "\n",
    "# define the namespace mapping\n",
    "ns = {\"rss\": \"http://purl.org/rss/1.0/\"}\n",
    "\n",
    "# loop through all the <item> elements and extract the victim name and ransomware name\n",
    "for item in root.xpath(\"//item\", namespaces=ns):\n",
    "    link = item.xpath(\"./link/text()\", namespaces=ns)[0]\n",
    "    title = item.xpath(\"./title/text()\", namespaces=ns)[0]\n",
    "    try:\n",
    "        actor = re.search(r'Actor\\s*:\\s*(\\w+)', title).group(1)\n",
    "    except:\n",
    "        continue\n",
    "    # print(\"Actor:\", actor)\n",
    "    # Extracting the victim\n",
    "    victim = re.search(r'Victim\\s*:\\s*(.*)(?!.*\\bDate\\s*:\\s*\\d{4}-\\d{2}-\\d{2})', title).group(1).strip()\n",
    "    if \"http\" in victim:\n",
    "        victim = victim.replace(\"https://\",\"\")\n",
    "        # print(f'cleaned: {victim}')\n",
    "        v_response = requests.get(f'https://unshorten.me/json/{victim}')\n",
    "        v_content = json.loads(v_response.content)\n",
    "        if v_content['success'] == \"true\":\n",
    "            victim = \"success: \" + v_content['resolved_url']\n",
    "        else:\n",
    "            victim = \"error\"\n",
    "    print(victim)\n",
    "    # Extracting the date\n",
    "    date = re.search(r'Date\\s*:\\s*(\\d{4}-\\d{2}-\\d{2})', title).group(1)\n",
    "    # print(\"Date:\", date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'victim_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m     victim_description \u001b[39m=\u001b[39m table\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mtd\u001b[39m\u001b[39m'\u001b[39m, text\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDescription\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mfind_next_sibling(\u001b[39m'\u001b[39m\u001b[39mtd\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mget_text()\n\u001b[1;32m     26\u001b[0m     uploaded_date \u001b[39m=\u001b[39m table\n\u001b[0;32m---> 27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mvictim_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'victim_name' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "url = 'https://www.redpacketsecurity.com/category/ransomware/'\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "blog_links = []\n",
    "for link in soup.find_all('a', {'rel': 'bookmark'}):\n",
    "    blog_links.append(link.get('href'))\n",
    "\n",
    "for link in blog_links:\n",
    "    r = requests.get(link)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    # Extract ransomware name from page title\n",
    "    title = soup.find('title').get_text()\n",
    "    ransomware_name = re.search(r'(?<=Ransomware Report: )(.*)', title).group(1)\n",
    "    \n",
    "    # Extract victim name, description, and uploaded date from HTML table\n",
    "    table = soup.find('table', {'class': 'wp-block-table'})\n",
    "    victim_name = table.find('td', text='Victim').find_next_sibling('td').get_text()\n",
    "    victim_description = table.find('td', text='Description').find_next_sibling('td').get_text()\n",
    "    uploaded_date = table\n",
    "print(f'{victim_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LockBit 3.0 baysideinteriors[.]com https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-baysideinteriors-com/ 2023-04-09 \n",
      "LockBit 3.0 bhrcorp[.]org https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-bhrcorp-org/ 2023-04-07 \n",
      "Karakurt Officeworks Inc https://www.redpacketsecurity.com/karakurt-ransomware-victim-officeworks-inc/ 2023-04-07 \n",
      "LockBit 3.0 tf-amd[.]com https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-tf-amd-com/ 2023-04-06 \n",
      "LockBit 3.0 tf-amd[.]com[.]my https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-tf-amd-com-my-2/ 2023-04-06 \n",
      "LockBit 3.0 nestseekers[.]com https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-nestseekers-com/ 2023-04-06 \n",
      "LockBit 3.0 tf-amd[.]com[.]my https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-tf-amd-com-my/ 2023-04-06 \n",
      "LockBit 3.0 nautic[.]com https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-nautic-com/ 2023-04-06 \n",
      "LockBit 3.0 turncommerce[.]com https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-turncommerce-com/ 2023-04-06 \n",
      "LockBit 3.0 masrl[.]com https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-masrl-com/ 2023-04-05 \n",
      "LockBit 3.0 omscomponents[.]it https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-omscomponents-it/ 2023-04-05 \n",
      "LockBit 3.0 olympia[.]org https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-olympia-org/ 2023-04-05 \n",
      "LockBit 3.0 tvh[.]com https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-tvh-com/ 2023-04-05 \n",
      "LockBit 3.0 aralaw[.]cr https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-aralaw-cr/ 2023-04-04 \n",
      "LockBit 3.0 garrottbros[.]com https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-garrottbros-com/ 2023-04-04 \n",
      "LockBit 3.0 vernegroup[.]com https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-vernegroup-com/ 2023-04-04 \n",
      "LockBit 3.0 vissan[.]com[.]vn https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-vissan-com-vn/ 2023-04-04 \n",
      "LockBit 3.0 thened[.]com https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-thened-com/ 2023-04-04 \n",
      "LockBit 3.0 revvaviation[.]com https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-revvaviation-com/ 2023-04-03 \n",
      "LockBit 3.0 gdz[.]com https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-gdz-com/ 2023-04-03 \n",
      "RansomHouse Aero Engine Solution INC https://www.redpacketsecurity.com/ransomhouse-ransomware-victim-aero-engine-solution-inc/ 2023-04-03 \n",
      "Cl0p LASOTEL[.]FR https://www.redpacketsecurity.com/cl0p-ransomware-victim-lasotel-fr/ 2023-04-03 \n",
      "LockBit 3.0 p-and-r[.]com https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-p-and-r-com/ 2023-04-02 \n",
      "LockBit 3.0 semsinc[.]net https://www.redpacketsecurity.com/lockbit-3-0-ransomware-victim-semsinc-net/ 2023-04-01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/2x8p3yd56d9f5h98km6zwtjh0000gn/T/ipykernel_16962/3606908866.py:24: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  description = entry.find(\"strong\", text=\"Description\")\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import whois\n",
    "\n",
    "# Make a GET request to the website\n",
    "url = \"https://www.redpacketsecurity.com/category/ransomware/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all the blog post titles and print them\n",
    "blog_entries = soup.find_all(\"article\", class_=\"small\")\n",
    "for entry in blog_entries:\n",
    "    title = entry.find(\"h4\", class_=\"entry-title\")\n",
    "    victim = title.text.split(\"Ransomware Victim: \")[1].split()\n",
    "    victim = ' '.join(victim)\n",
    "    ransomware = title.text.split(\"Ransomware Victim: \")[0].split()\n",
    "    ransomware = ' '.join(ransomware)\n",
    "    link = title.a[\"href\"]\n",
    "    date = entry.find(\"span\", class_=\"mg-blog-date\")\n",
    "    date = pd.to_datetime(date.a.text).strftime('%Y-%m-%d')\n",
    "    description = entry.find(\"strong\", text=\"Description\")\n",
    "    if description:\n",
    "        description_text = description.parent.text.split(\"Description\")[1].strip()\n",
    "    else:\n",
    "        description_text = \"\"\n",
    "    print(ransomware, victim, link, date, description_text)\n",
    "\n",
    "    # title = entry.find(\"h4\", class_=\"entry-title\")\n",
    "    # victim = title.text.split(\"Ransomware Victim: \")[1].split()\n",
    "    # victim = ' '.join(victim)\n",
    "    # ransomware = title.text.split(\"Ransomware Victim: \")[0].split()\n",
    "    # ransomware = ' '.join(ransomware)\n",
    "    # link = title.a[\"href\"]\n",
    "    # date = entry.find(\"span\", class_=\"mg-blog-date\")\n",
    "    # date = pd.to_datetime(date.a.text).strftime('%Y-%m-%d')\n",
    "    # # print(f\"{date} {ransomware} - {victim} ({link})\")\n",
    "    # # Find the table row that contains the \"Description\" label\n",
    "    # description_row = soup.find(\"strong\", text=\"Description\")\n",
    "    # print(description_row)\n",
    "    # Get the text from the next row in the table\n",
    "    # text_to_scrape = description_row.find_next_sibling(\"tr\").text.strip()\n",
    "    # print(text_to_scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade python-whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois\n",
    "\n",
    "def get_company_name(domain):\n",
    "    try:\n",
    "        w = whois.whois(domain)\n",
    "        return w.text\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"ummm\"\n",
    "\n",
    "# Example usage\n",
    "domain = 'wwe.com'\n",
    "company_name = get_company_name(domain)\n",
    "print(company_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set URL Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_url = \"https://www.inoreader.com/stream/user/1004920918/tag/Py%3A%20Ransomware%20monitor\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import CSV Database\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_csv = pd.read_csv('cve_db.csv')\n",
    "# df_csv.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull RSS Feed\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the RSS feed\n",
    "response = requests.get(rss_url)\n",
    "\n",
    "# Parse the XML feed using lxml\n",
    "root = etree.fromstring(response.content)\n",
    "\n",
    "# define the namespace used in the RSS feed\n",
    "ns = {'rss': 'http://www.w3.org/2005/Atom'}\n",
    "\n",
    "# Get the list of items in the feed\n",
    "items = root.xpath(\"//item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "# parse the RSS feed\n",
    "# rss = etree.parse('rss_feed.xml')\n",
    "\n",
    "# iterate over the items in the feed\n",
    "for item in items:\n",
    "    # extract the victim name\n",
    "    victim_name = title = item.xpath(\"title\")[0].text.replace('\\n',' ')\n",
    "    \n",
    "    # # extract the ransomware name\n",
    "    # ransomware_name = item.xpath('.//rss:div/text()', namespaces=ns)[0]\n",
    "    \n",
    "    # # extract the source URL\n",
    "    # source_url = item.xpath('.//rss:link/text()', namespaces=ns)[0]\n",
    "    \n",
    "    # # extract the source title\n",
    "    # source_title = item.xpath('.//rss:title/text()', namespaces=ns)[0]\n",
    "    \n",
    "    # print the extracted information\n",
    "    print(f\"Victim name: {victim_name}\")\n",
    "    # print(f\"Ransomware name: {ransomware_name}\")\n",
    "    # print(f\"Source URL: {source_url}\")\n",
    "    # print(f\"Source title: {source_title}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define an empty list to store the CVE data\n",
    "# cve_data = []\n",
    "# # Set to track unique CVEs\n",
    "# unique_cve = set()\n",
    "# Set current time variable\n",
    "current_time = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Iterate over the items and extract the CVE data\n",
    "for item in items:\n",
    "    title = item.xpath(\"title\")[0].text.replace('\\n',' ')\n",
    "    title = title.replace('\\t',' ')\n",
    "    title = title.replace('  ',' ')\n",
    "    link = item.xpath(\"link\")[0].text\n",
    "    description = item.xpath(\"description\")[0].text\n",
    "    pub_date = item.xpath(\"pubDate\")[0].text\n",
    "    pub_date = pd.to_datetime(pub_date[5:])\n",
    "\n",
    "    # Extract the CVE identifiers from the description\n",
    "    cves = re.findall(r'(CVE-\\d{4}-\\d{4,7})', description)\n",
    "\n",
    "    # Append the CVE data to the list\n",
    "    for cve in cves:\n",
    "        cve_data.append({\"cve_ID\": cve,\n",
    "        \"tweet_content\": title, \n",
    "        \"tweet_url\": link, \n",
    "        \"date_scraped\": current_time, \n",
    "        \"date_published\": pd.to_datetime(pub_date).strftime('%Y-%m-%d'),\n",
    "        \"report_key\": cve+link\n",
    "        })\n",
    "        unique_cve.update(cves)\n",
    "\n",
    "# Create a DataFrame from the CVE data\n",
    "df_cve_main = pd.DataFrame(cve_data)\n",
    "df_cve_main.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Older Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Locate all older entries that are not in KEV\n",
    "df_missing_nvd = df_csv.loc[(df_csv['kev_present'] == False)] #CHECK - ensure same as what is being input for missing fields\n",
    "# # Combine missing entries with CVE list\n",
    "df_cve_main = pd.concat([df_missing_nvd,df_cve_main],ignore_index=True)\n",
    "# # Remove duplicates\n",
    "df_cve_main.drop_duplicates('report_key', inplace = True)\n",
    "\n",
    "# Length before concat\n",
    "before = len(unique_cve)\n",
    "# COMMENT OUT TO PREVENT UPDATE OF OLDER ENTRIES\n",
    "unique_cve.update(df_cve_main['cve_ID'])\n",
    "# Length after concat\n",
    "after = len(unique_cve)\n",
    "# Print stats\n",
    "print(f'Before: {before}, After: {after}')\n",
    "# print(df_cve_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvd_table = []\n",
    "default_zero = pd.to_datetime('1900-01-01').strftime('%Y-%m-%d')\n",
    "current_time = pd.Timestamp.now()\n",
    "\n",
    "for x in unique_cve:\n",
    "    nvd_response = requests.get(f'{NVD_BASE_URL}{x}')\n",
    "    json_data = nvd_response.json()\n",
    "    \n",
    "    try:\n",
    "        nvd_description = json_data['vulnerabilities'][0]['cve']['descriptions'][0]['value']\n",
    "        nvd_present = True\n",
    "    except:\n",
    "        nvd_description = 'no data'\n",
    "        nvd_present = False\n",
    "    try:\n",
    "        cve_dict = json_data['vulnerabilities'][0]['cve']\n",
    "    except:\n",
    "        cve_dict = {}\n",
    "\n",
    "    nvd_published = cve_dict.get('published',default_zero)\n",
    "    nvd_lastModified = cve_dict.get('lastModified',default_zero)\n",
    "    nvd_vulnStatus = cve_dict.get('vulnStatus','*no data*')\n",
    "    nvd_cisaExploitAdd = cve_dict.get('cisaExploitAdd',default_zero)\n",
    "    nvd_cisaVulnerabilityName = cve_dict.get('cisaVulnerabilityName','*no data*')\n",
    "    bulk_references = cve_dict.get('references','*no data*')\n",
    "    nvd_references = []\n",
    "    if bulk_references == '*no data*':\n",
    "        next\n",
    "    else:\n",
    "        for i in bulk_references:\n",
    "            nvd_references.append(i['url'])\n",
    "    try:\n",
    "        cvss_data_dict = json_data['vulnerabilities'][0]['cve']['metrics']['cvssMetricV31'][0]['cvssData']\n",
    "    except:\n",
    "        cvss_data_dict = {}\n",
    "\n",
    "    nvd_attackVector = cvss_data_dict.get('attackVector','*no data*')\n",
    "    nvd_attackComplexity = cvss_data_dict.get('attackComplexity','*no data*')\n",
    "    nvd_privilegesRequired = cvss_data_dict.get('privilegesRequired','*no data*')\n",
    "    nvd_userInteraction = cvss_data_dict.get('userInteraction','no data')\n",
    "    nvd_baseScore = cvss_data_dict.get('baseScore','*no data*')\n",
    "    nvd_baseSeverity = cvss_data_dict.get('baseSeverity','*no data*')\n",
    "\n",
    "    try:\n",
    "        nvd_exploitabilityScore = json_data['vulnerabilities'][0]['cve']['metrics']['cvssMetricV31'][0]['exploitabilityScore']\n",
    "    except:\n",
    "        nvd_exploitabilityScore = '*no data*'\n",
    "    try:\n",
    "        nvd_impactScore = json_data['vulnerabilities'][0]['cve']['metrics']['cvssMetricV31'][0]['impactScore']\n",
    "    except:\n",
    "        nvd_impactScore = ''\n",
    "\n",
    "    if nvd_cisaExploitAdd == default_zero:\n",
    "        kev_present = False\n",
    "        kev_dateDelta = 0\n",
    "        kev_category = \"1. Not in KEV\"\n",
    "    else:\n",
    "        kev_present = True\n",
    "        kev_dateDelta = pd.to_datetime(current_time) - pd.to_datetime(nvd_cisaExploitAdd)\n",
    "        kev_dateDelta = kev_dateDelta.days\n",
    "        if kev_dateDelta > 30:\n",
    "            kev_category = \"3. KEV, Old (>30)\"\n",
    "        else:\n",
    "            kev_category = \"2. KEV, New (0-30)\" \n",
    "\n",
    "    print(f'{x}\\nBase Score: {nvd_baseScore}\\nKEV: {kev_category} || Added {nvd_cisaExploitAdd} ({kev_dateDelta})')\n",
    "    \n",
    "    nvd_table.append({'cve_ID':x,\n",
    "                      'nvd_description': nvd_description, \n",
    "                      'nvd_published': pd.to_datetime(nvd_published).strftime('%Y-%m-%d'), \n",
    "                      'nvd_lastModified': pd.to_datetime(nvd_lastModified).strftime('%Y-%m-%d'),\n",
    "                      'nvd_vulnStatus': nvd_vulnStatus,\n",
    "                      'nvd_cisaExploitAdd': pd.to_datetime(nvd_cisaExploitAdd).strftime('%Y-%m-%d'),\n",
    "                      'nvd_cisaVulnerabilityName': nvd_cisaVulnerabilityName,\n",
    "                      'nvd_references': nvd_references,\n",
    "                      'nvd_attackVector': nvd_attackVector,\n",
    "                      'nvd_attackComplexity': nvd_attackComplexity,\n",
    "                      'nvd_privilegesRequired': nvd_privilegesRequired,\n",
    "                      'nvd_userInteraction': nvd_userInteraction,\n",
    "                      'nvd_baseScore': nvd_baseScore,\n",
    "                      'nvd_baseSeverity': nvd_baseSeverity,\n",
    "                      'nvd_exploitabilityScore': nvd_exploitabilityScore,\n",
    "                      'nvd_impactScore': nvd_impactScore,\n",
    "                      'nvd_present': nvd_present,\n",
    "                      'kev_present': kev_present,\n",
    "                      'kev_dateDelta': kev_dateDelta,\n",
    "                      'kev_category': kev_category\n",
    "                      })\n",
    "    time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nvd = pd.DataFrame(nvd_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine dfs\n",
    "for x in df_nvd['cve_ID']:\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['kev_present']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['kev_present']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_present']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_present']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_published']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_published']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_lastModified']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_lastModified']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_vulnStatus']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_vulnStatus']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_cisaExploitAdd']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_cisaExploitAdd']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_cisaVulnerabilityName']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_cisaVulnerabilityName']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_description']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_description']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_attackVector']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_attackVector']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_attackComplexity']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_attackComplexity']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_privilegesRequired']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_privilegesRequired']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_userInteraction']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_userInteraction']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_baseScore']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_baseScore']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_baseSeverity']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_baseSeverity']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_exploitabilityScore']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_exploitabilityScore']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_impactScore']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_impactScore']].values\n",
    "    # df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['nvd_references']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['nvd_references']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['kev_dateDelta']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['kev_dateDelta']].values\n",
    "    df_cve_main.loc[(df_cve_main['cve_ID'] == x), ['kev_category']] = df_nvd.loc[(df_nvd['cve_ID'] == x), ['kev_category']].values\n",
    "# print(df_cve_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated_db = pd.concat([df_csv,df_cve_main],ignore_index=True)\n",
    "df_updated_db.drop_duplicates('report_key', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'context' column\n",
    "def context(tweet):\n",
    "    \n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.replace('#','')\n",
    "    poc = ['concept','proof','poc','exploit code','poc_link']\n",
    "    exploitation = ['zeroday','actively', 'active', 'wild','0day','0-day','zero','exploitation','zero-day']\n",
    "    c_value = 'none'\n",
    "\n",
    "    for keyword in poc:\n",
    "        if bool(re.search(keyword,tweet)):\n",
    "            # print(tweet)\n",
    "            # print(f'{keyword}: {bool(re.search(keyword,tweet))}')\n",
    "            c_value = 'poc'\n",
    "    for keyword in exploitation:\n",
    "        if bool(re.search(keyword,tweet)):\n",
    "            # print(tweet)\n",
    "            # print(f'{keyword}: {bool(re.search(keyword,tweet))}')\n",
    "            c_value = 'exploitation'\n",
    "    return c_value\n",
    "\n",
    "df_updated_db['tweet_exploitContext'] = df_updated_db['tweet_content'].apply(context)\n",
    "df_cve_main['tweet_exploitContext'] = df_updated_db['tweet_exploitContext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated_db.to_csv('cve_db.csv', mode='w', header=True, index=False)\n",
    "# df_updated_db.to_excel('cve_db.xlsx', index = None, header=True)\n",
    "# df_updated_db.to_csv('test_success.csv',mode='w',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into a pandas dataframe\n",
    "# df = pd.read_csv('path/to/csv')\n",
    "\n",
    "# Create a new workbook object\n",
    "wb = openpyxl.Workbook()\n",
    "\n",
    "# Create a new worksheet object\n",
    "ws = wb.create_sheet('Sheet1')\n",
    "\n",
    "# Write data from dataframe to worksheet\n",
    "for r in dataframe_to_rows(df_updated_db, index=False, header=True):\n",
    "    ws.append(r)\n",
    "\n",
    "# Define the table range\n",
    "table_range = ws.dimensions\n",
    "\n",
    "# Add table to worksheet\n",
    "tab = Table(displayName=\"table1\", ref=table_range)\n",
    "ws.add_table(tab)\n",
    "\n",
    "# Save the workbook\n",
    "wb.save('cve_db.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Make a GET request to the website\n",
    "url = \"https://www.redpacketsecurity.com/category/ransomware/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all the blog post titles and extract the links\n",
    "blog_titles = soup.find_all(\"h4\", class_=\"entry-title\")\n",
    "links = [title.a[\"href\"] for title in blog_titles]\n",
    "\n",
    "# Loop over each link and extract the description text\n",
    "for link in links:\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    description = soup.find(\"strong\", text=\"Description\").parent.parent.split(<td>)\n",
    "    print(description)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
